# -Spark-Multi-Format-Data-Lake-Pipeline
A production-ready PySpark pipeline that ingests heterogeneous data files (JSON, CSV, Parquet, DOCX/TXT) into Apache Iceberg tables, then merges the data into existing databases on MinIO object storage. Designed for data lakes where files have unpredictable or varying schemas.
